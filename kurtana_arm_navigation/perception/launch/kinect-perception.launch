<?xml version="1.0"?>
<launch>
  <!-- send planning environment parameters -->
  <include file="$(find kurtana_arm_navigation)/config/launch/planning_environment.launch" />

  <include file="$(find kinect_camera)/launch/kinect_node.launch" />

  <!-- drop frames to speed things up; the Kinect publishes at around 10 Hz, which is way too much
       for the collision map, so drop 9 out of 10 frames -->
  <node pkg="topic_tools" type="drop" name="drop" args="/kinect/depth/points 9 10 /kinect/depth/points_drop" />

  <!-- need to clear known objects from scans -->
  <node pkg="planning_environment" type="clear_known_objects" name="clear_known_objects" output="screen">
    <remap from="cloud_in" to="kinect/depth/points_drop" />
    <remap from="cloud_out" to="kinect_depth_cleared_from_known" />
    <param name="sensor_frame" type="string" value="kinect_depth" />
    <param name="fixed_frame" type="string" value="kurtana_rackplate_link" /> <!-- TODO: use world frame (e.g., "odom_combined", "map") -->
    <param name="object_padd" type="double" value="0.02" />
    <param name="object_scale" type="double" value="1.0" />
  </node>

   <node pkg="point_cloud_converter" name="point_cloud_converter_preself" type="point_cloud_converter" output="screen">
     <remap from="/points_in" to="/kinect_depth_cleared_from_known" />
     <remap from="/points2_out" to="/kinect_depth_cleared_from_known2" />
   </node>

  <!-- displaying known model markers -->
  <node pkg="planning_environment" name="display_planner_collision_model_environment_server"
      type="display_planner_collision_model" respawn="false" output="screen">
    <param name="skip_collision_map" type="bool" value="false" />
    <param name="prefix" type="string" value="/environment_server" />
  </node>

   <node pkg="planning_environment" name="display_planner_collision_model_ik" type="display_planner_collision_model" respawn="false" output="screen">
    <param name="skip_collision_map" type="bool" value="false" />
    <param name="prefix" type="string" value="/arm_kinematics" />
  </node>

  <!-- need to individually self filter scans -->
  <node pkg="robot_self_filter" type="self_filter" respawn="true" name="self_filter" output="screen">

    <!-- The topic for the input cloud -->
    <remap from="cloud_in" to="/kinect_depth_cleared_from_known2" />

    <!-- The topic for the output cloud -->
    <remap from="cloud_out" to="kinect_depth_robot_filtered2" />

    <!-- The frame of the sensor used to obtain the data to be
       filtered; This parameter is optional. If it is not specified,
       shadow points will be considered outside -->
    <param name="sensor_frame" type="string" value="kinect_depth" />

    <param name="subsample_value" type="double" value=".01"/>

    <rosparam command="load" file="$(find kurtana_arm_navigation)/perception/config/self_filter.yaml" />
  </node>

     <!-- cut the kinect_depth_robot_filtered2 below a specific z-value (below the table) to avoid wrong table detections (e.g. on the floor) -->
   <node pkg="nodelet" type="nodelet" name="pcl_manager" args="manager" output="screen" />
   <!-- run a passthrough filter to clean NaNs -->
   <node pkg="nodelet" type="nodelet" name="passthrough" args="load pcl/PassThrough pcl_manager" output="screen">
    <remap from="~input" to="kinect_depth_robot_filtered2" />
	<remap from="~output" to="kinect_depth_passthrough_filtered2" />
    <rosparam>
      filter_field_name: z
      filter_limit_min: 0.15
      filter_limit_max: 1.2
      filter_limit_negative: False
    </rosparam>
   </node>

  <node pkg="point_cloud_converter" name="point_cloud_converter_postself" type="point_cloud_converter">
	<remap from="/points2_in" to="/kinect_depth_passthrough_filtered2" />
        <remap from="/points_out" to="/kinect_depth_fully_filtered" />
  </node>

  <!-- start collision map -->
  <include file="$(find kurtana_arm_navigation)/perception/launch/collision_map_self_occ.launch" />

</launch>
